{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://www.learnpytorch.io/04_pytorch_custom_datasets/\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "https://www.learnpytorch.io/04_pytorch_custom_datasets/\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "04. PyTorch 自定义数据集\n",
    "In the last notebook, notebook 03, we looked at how to build computer vision models on an in-built dataset in PyTorch (FashionMNIST).\n",
    "在上一个笔记本（笔记本 03）中，我们研究了如何在 PyTorch (FashionMNIST) 的内置数据集上构建计算机视觉模型。\n",
    "\n",
    "The steps we took are similar across many different problems in machine learning.\n",
    "对于机器学习中的许多不同问题，我们采取的步骤都是相似的。\n",
    "\n",
    "Find a dataset, turn the dataset into numbers, build a model (or find an existing model) to find patterns in those numbers that can be used for prediction.\n",
    "查找数据集，将数据集转换为数字，构建模型（或查找现有模型）以查找这些数字中可用于预测的模式。\n",
    "\n",
    "PyTorch has many built-in datasets used for a wide number of machine learning benchmarks, however, you'll often want to use your own custom dataset.\n",
    "PyTorch 有许多内置数据集，用于大量机器学习基准测试，但是，您通常希望使用自己的自定义数据集。\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "什么是自定义数据集？\n",
    "A custom dataset is a collection of data relating to a specific problem you're working on.\n",
    "自定义数据集是与您正在处理的特定问题相关的数据集合。\n",
    "\n",
    "In essence, a custom dataset can be comprised of almost anything.\n",
    "本质上，自定义数据集几乎可以由任何内容组成。\n",
    "\n",
    "For example, if we were building a food image classification app like Nutrify, our custom dataset might be images of food.\n",
    "例如，如果我们正在构建像Nutrify这样的食物图像分类应用程序，我们的自定义数据集可能是食物图像。\n",
    "\n",
    "Or if we were trying to build a model to classify whether or not a text-based review on a website was positive or negative, our custom dataset might be examples of existing customer reviews and their ratings.\n",
    "或者，如果我们尝试构建一个模型来对网站上基于文本的评论是正面还是负面进行分类，那么我们的自定义数据集可能是现有客户评论及其评级的示例。\n",
    "\n",
    "Or if we were trying to build a sound classification app, our custom dataset might be sound samples alongside their sample labels.\n",
    "或者，如果我们尝试构建声音分类应用程序，我们的自定义数据集可能是声音样本及其样本标签。\n",
    "\n",
    "Or if we were trying to build a recommendation system for customers purchasing things on our website, our custom dataset might be examples of products other people have bought.\n",
    "或者，如果我们试图为在我们网站上购买商品的客户构建推荐系统，我们的自定义数据集可能是其他人购买过的产品的示例。\n",
    "\n",
    "\n",
    "PyTorch 包含许多现有函数，可加载TorchVision 、 TorchText 、 TorchAudio和TorchRec域库中的各种自定义数据集。\n",
    "\n",
    "\n",
    "但有时这些现有的功能可能还不够。\n",
    "\n",
    "\n",
    "在这种情况下，我们总是可以继承torch.utils.data.Dataset并根据我们的喜好自定义它。\n",
    "\n",
    "\n",
    "我们要介绍的内容\n",
    "We're going to be applying the PyTorch Workflow we covered in notebook 01 and notebook 02 to a computer vision problem.\n",
    "我们将把笔记本 01和笔记本 02中介绍的 PyTorch 工作流程应用于计算机视觉问题。\n",
    "\n",
    "But instead of using an in-built PyTorch dataset, we're going to be using our own dataset of pizza, steak and sushi images.\n",
    "但我们将使用我们自己的披萨、牛排和寿司图像数据集，而不是使用内置的 PyTorch 数据集。\n",
    "\n",
    "The goal will be to load these images and then build a model to train and predict on them.\n",
    "目标是加载这些图像，然后构建模型来训练和预测它们。\n",
    "\n",
    "\n",
    "我们要建造什么。我们将使用 torchvision.datasets 以及我们自己的自定义 Dataset 类来加载食物图像，\n",
    "然后我们将构建一个 PyTorch 计算机视觉模型，希望能够对它们进行分类。\n",
    "\n",
    "Specifically, we're going to cover:\n",
    "具体来说，我们将涵盖：\n",
    "\n",
    "\n",
    "0.导入PyTorch并设置与设备无关的代码     让我们加载 PyTorch，然后按照最佳实践将我们的代码设置为与设备无关。\n",
    "\n",
    "1. 获取数据                          我们将使用我们自己的披萨、牛排和寿司图像的自定义数据集。\n",
    "\n",
    "2. 与数据合而为一（数据准备）           在任何新的机器学习问题开始时，了解您正在使用的数据至关重要。在这里，\n",
    "                                    我们将采取一些步骤来弄清楚我们拥有哪些数据。\n",
    "\n",
    "3. 转换数据                          通常，您获得的数据不会 100% 准备好用于机器学习模型，\n",
    "                                    在这里我们将了解可以采取的一些步骤来转换图像，以便它们准备好用于模型。\n",
    "\n",
    "\n",
    "4. 使用ImageFolder加载数据(选项 1)     PyTorch 有许多针对常见数据类型的内置数据加载函数。如果我们的图像采用标准图像分类格式， \n",
    "                                    ImageFolder会很有帮助。\n",
    "\n",
    "5. 使用自定义 Dataset 集加载图像数据    如果 PyTorch 没有内置函数来加载数据怎么办? \n",
    "                                    这是我们可以构建自己的torch.utils.data.Dataset的自定义子类的地方。    \n",
    "\n",
    "6. 其他形式的变换（数据增强）           数据增强是扩展训练数据多样性的常用技术。在这里，我们将探索torchvision的一些内置数据增强功能。      \n",
    "\n",
    "7.模型0：没有数据增强的TinyVGG          到这个阶段，我们将准备好数据，让我们构建一个能够拟合它的模型。我们还将创建一些训练和测试函数来训练和评估我们的模型。\n",
    "\n",
    "8. 探索损失曲线                     损失曲线是了解模型如何随着时间的推移进行训练/改进的好方法。它们也是查看模型是否欠拟合或过拟合的好方法。\n",
    "\n",
    "9. 模型 1：具有数据增强功能的 TinyVGG   到目前为止，我们已经尝试了一种没有 的模型，那么我们尝试一个带有数据增强的模型怎么样？\n",
    "\n",
    "10. 比较模型结果                    让我们比较不同模型的损失曲线，看看哪个模型表现更好，并讨论一些提高性能的选项。\n",
    "\n",
    "11. 对自定义图像进行预测            我们的模型接受了披萨、牛排和寿司图像数据集的训练。在本节中，我们将介绍如何使用经过训练的模型来预测现有数据集之外的图像。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "0.导入PyTorch并设置与设备无关的代码\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Note: this notebook requires torch >= 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find data/pizza_steak_sushi directory, creating one...\n",
      "Downloading pizza, steak, sushi data...\n",
      "Unzipping pizza, steak, sushi data...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. 获取数据\n",
    "\n",
    "首先我们需要一些数据。\n",
    "\n",
    "\n",
    "就像任何优秀的烹饪节目一样，一些数据已经为我们准备好了。\n",
    "\n",
    "\n",
    "我们要从小事做起。\n",
    "\n",
    "\n",
    "因为我们还不打算训练最大的模型或使用最大的数据集。\n",
    "\n",
    "\n",
    "机器学习是一个迭代过程，从小处开始，让某些东西发挥作用，并在必要时增加。\n",
    "\n",
    "\n",
    "我们将使用的数据是Food101 数据集的子集。\n",
    "\n",
    "\n",
    "Food101 是流行的计算机视觉基准，因为它包含 101 种不同食物的 1000 张图像，\n",
    "总共 101,000 张图像（75,750 个训练图像和 25,250 个测试图像）。\n",
    "\n",
    "\n",
    "你能想到 101 种不同的食物吗？\n",
    "\n",
    "\n",
    "你能想出一个计算机程序来对 101 种食物进行分类吗？\n",
    "\n",
    "我可以。\n",
    "\n",
    "\n",
    "机器学习模型！\n",
    "\n",
    "\n",
    "具体来说，是我们在笔记本 03中介绍的 PyTorch 计算机视觉模型。\n",
    "\n",
    "\n",
    "不过，我们不会从 101 类食物开始，而是从 3 类开始：披萨、牛排和寿司。\n",
    "\n",
    "我们将从随机的 10% 开始（从小处开始，必要时增加），而不是每类 1,000 张图像。\n",
    "\n",
    "\n",
    "如果您想查看数据的来源，可以查看以下资源：\n",
    "\n",
    "\n",
    "原始Food101 数据集和论文网站。\n",
    "\n",
    "torchvision.datasets.Food101 - 我为此笔记本下载的数据版本。\n",
    "\n",
    "extras/04_custom_data_creation.ipynb - 我用来格式化 Food101 数据集以用于此笔记本的笔记本。\n",
    "\n",
    "data/pizza_steak_sushi.zip - 来自 Food101 的披萨、牛排和寿司图像的 zip 存档，使用上面链接的笔记本创建。\n",
    "\n",
    "让我们编写一些代码来从 GitHub 下载格式化数据。\n",
    "\n",
    "\n",
    "注意：我们即将使用的数据集已根据我们的用途进行了预先格式化。\n",
    "但是，您通常必须针对您正在处理的任何问题来格式化自己的数据集。这是机器学习领域的常规做法。\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        zip_ref.extractall(image_path)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "2. 与数据合而为一（数据准备）\n",
    "Dataset downloaded! 数据集已下载！\n",
    "\n",
    "Time to become one with it.\n",
    "是时候与它合而为一了。\n",
    "\n",
    "This is another important step before building a model.\n",
    "这是构建模型之前的另一个重要步骤。\n",
    "\n",
    "As Abraham Lossfunction said...\n",
    "正如亚伯拉罕·损失函数所说……\n",
    "\n",
    "If I had 8 hours to build a machine learning model, I'd spend the first 6 hours preparing my dataset.\n",
    "\n",
    "数据准备至关重要。在构建模型之前，先与数据融为一体。问：我在这里想做什么？资料来源： @mrdbourke 推特。\n",
    "\n",
    "\n",
    "检查数据并与之合而为一是什么？\n",
    "\n",
    "\n",
    "在开始项目或构建任何类型的模型之前，了解您正在使用哪些数据非常重要。\n",
    "\n",
    "\n",
    "在我们的例子中，我们有标准图像分类格式的披萨、牛排和寿司的图像。\n",
    "\n",
    "\n",
    "图像分类格式在以特定类名标题的单独目录中包含单独的图像类。\n",
    "\n",
    "\n",
    "例如，所有pizza图像都包含在pizza/目录中。\n",
    "\n",
    "这种格式在许多不同的图像分类基准中都很流行，包括ImageNet （最流行的计算机视觉基准数据集）。\n",
    "\n",
    "您可以在下面看到存储格式的示例，图像数量是任意的。\n",
    "\n",
    "pizza_steak_sushi/ <- overall dataset folder\n",
    "    train/ <- training images\n",
    "        pizza/ <- class name as folder name\n",
    "            image01.jpeg\n",
    "            image02.jpeg\n",
    "            ...\n",
    "        steak/\n",
    "            image24.jpeg\n",
    "            image25.jpeg\n",
    "            ...\n",
    "        sushi/\n",
    "            image37.jpeg\n",
    "            ...\n",
    "    test/ <- testing images\n",
    "        pizza/\n",
    "            image101.jpeg\n",
    "            image102.jpeg\n",
    "            ...\n",
    "        steak/\n",
    "            image154.jpeg\n",
    "            image155.jpeg\n",
    "            ...\n",
    "        sushi/\n",
    "            image167.jpeg\n",
    "            ...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in 'data/pizza_steak_sushi'.\n",
      "There are 3 directories and 0 images in 'data/pizza_steak_sushi/test'.\n",
      "There are 0 directories and 19 images in 'data/pizza_steak_sushi/test/steak'.\n",
      "There are 0 directories and 31 images in 'data/pizza_steak_sushi/test/sushi'.\n",
      "There are 0 directories and 25 images in 'data/pizza_steak_sushi/test/pizza'.\n",
      "There are 3 directories and 0 images in 'data/pizza_steak_sushi/train'.\n",
      "There are 0 directories and 75 images in 'data/pizza_steak_sushi/train/steak'.\n",
      "There are 0 directories and 72 images in 'data/pizza_steak_sushi/train/sushi'.\n",
      "There are 0 directories and 78 images in 'data/pizza_steak_sushi/train/pizza'.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "目标是采用此数据存储结构并将其转换为可与 PyTorch 一起使用的数据集。\n",
    "\n",
    "\n",
    "注意：您使用的数据结构会根据您正在处理的问题而有所不同。\n",
    "但前提仍然是：与数据融为一体，然后找到一种方法将其最好地转换为与 PyTorch 兼容的数据集。\n",
    "\n",
    "\n",
    "我们可以通过编写一个小帮助函数来检查数据目录中的内容，以遍历每个子目录并计算存在的文件数。\n",
    "\n",
    "\n",
    "为此，我们将使用 Python 内置的os.walk() 。\n",
    "'''\n",
    "\n",
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Walks through dir_path returning its contents.\n",
    "  Args:\n",
    "    dir_path (str or pathlib.Path): target directory\n",
    "  \n",
    "  Returns:\n",
    "    A print out of:\n",
    "      number of subdiretories in dir_path\n",
    "      number of images (files) in each subdirectory\n",
    "      name of each subdirectory\n",
    "  \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "\n",
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "出色的！\n",
    "\n",
    "\n",
    "看起来每个训练类有大约 75 个图像，每个测试类有 25 个图像。\n",
    "\n",
    "\n",
    "这应该足以开始了。\n",
    "\n",
    "\n",
    "请记住，这些图像是原始 Food101 数据集的子集。\n",
    "\n",
    "\n",
    "您可以在数据创建笔记本中查看它们是如何创建的。\n",
    "\n",
    "\n",
    "当我们这样做时，让我们设置我们的训练和测试路径。\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dlfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
